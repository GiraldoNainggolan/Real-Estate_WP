- Hi, I am Shaun. I'm a Research Scientist
at Google Research. I research fairness and equality of AI, especially for marginalized groups, like people with disabilities. The main reason I came to
Google was to have impact on the technology that we use and the technology that's coming. My favorite part of this
job is working with people, both the people on my team,
but also in our research, we get to go out into the community and get feedback about
what we can be doing better and how we should be thinking
about the future of AI and how it's gonna affect people. You know, if you think
about how different people might engage with an AI system, one thing that you might consider is people will ask questions. "What is life like for
someone with a disability?" "What kinds of things do people
with disabilities enjoy?" And it's not clear what the right answer is
to that kind of question. What should you say? And I think one of the
things we want to avoid is to say, "Oh, that's a sensitive topic, "so we can't answer that." From my perspective, that means we've lost because now, we are missing
out on opportunities to teach people and to
be helpful to people. We want systems that work for everybody. You know, AI has to be for everybody. AI bias is a huge problem and we have to solve it
in many different ways, from data to algorithms to user interface. One way to address bias and harmful content is to make sure that our data sets are appropriate and are representative of
a wide variety of people. A lot of the work that our
team is doing is in helping to define guidelines for collecting data and to make sure that we have
data that's representative of a wide variety of people,
a wide variety of experiences, and a wide variety of perspectives. One way to keep on top of these issues is through having systems
that are transparent. So being able to understand
how AI systems work, what data they draw on, how they come to provide
certain kinds of feedback. I think a huge part of learning to use AI is also
applying critical thinking and not just taking the
first answer you get, but really trying to understand
why a particular answer came about, right? I think about AI systems not as a tool to give you answers, but
to help you get to answers. I use AI in my home life
also, we, a couple weeks ago, used AI to help come up
with a name for our pet. And so that was really
helpful just as a muse and as a way to, like, generate some ideas and have a little bit of fun. Dr. Bones is the name of my cat, yeah.