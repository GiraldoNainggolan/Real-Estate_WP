- In order to limit biases,
drift, and inaccuracies, AI models require humans to take action, like retraining models
on more diverse data sets and continuing to fine
tune them frequently. Humans must also consider
the inadvertent harms associated with using these AI tools. Let's examine some of the types of harm that AI can cause if used irresponsibly. First is allocative harm. An allocative harm is a
wrongdoing that occurs when an AI system's use or behavior withholds opportunities or
resources or information in domains that affect
a person's wellbeing. For example, if AI tools don't provide the same information to everyone, some people may be denied
access to education, healthcare, fair housing,
or other opportunities. Maybe a property manager
for an apartment complex uses an AI tool to screen applications for potential tenants. This AI tool uses the names and other identifying
information on these applications to help conduct background checks. One applicant is deemed a risk because of a low credit score, so they are denied the apartment and they lose the application fee. Later, the property manager realizes the software had
misidentified the applicant and ran a background
check on the wrong person. In this example, the applicant has experienced
an allocative harm because they were denied an opportunity and lost resources, both
affecting their wellbeing. Another type of harm AI can cause is quality-of-service harm. Quality-of-service harm is a
circumstance in which AI tools do not perform as well for
certain groups of people based on their identity. When speech recognition
technology was first developed, the training data didn't
have many examples of speech patterns exhibited
by people with disabilities, so the devices often struggled
to parse this type of speech, but this technology is still evolving. The next type of harm is
representational harm, an AI tool's reinforcement of the subordination of social groups based on their identities. For instance, the AI powering
a language translation app might associate certain
words with feminine or masculine traits, and choose gender specific translations based on those assumptions. Now, this is harmful because the result may be the erasure or alienation of social
groups due to built-in biases. Another type of harm associated with AI is social system harm. This harm refers to
macro-level societal effects that amplify existing class,
power, or privilege disparities or cause physical harm as a result of the development
or use of AI tools. As AI-generated images
become more realistic, there's concern about the
spread of disinformation, including deep fakes. Deepfakes are AI generated
fake photos or videos of real people saying or doing
things that they did not do. An example of a social system harm might be if a deepfake of
a school board candidate showed that person saying
something they didn't say. If it went viral, causing
them to lose the election, that would impact voters' perspectives, the way parents feel about
their school district, and the community in general. Because there would be
disinformation being spread on a large scale, this would
be a social system harm. Fortunately, new
technology is being created to detect Deepfakes. Some image generating tools
are putting digital watermarks on AI-generated images and videos to indicate who created them. Over time, deepfakes should become easier for computers to identify. AI users do need to be
aware of the difficulty of distinguishing between
AI-generated images and real images, and the consequences of
creating these deepfakes. Sometimes people can
share private information with an AI tool that could
be misused by others, like locking someone
out of an online account or surveilling them. These are examples of interpersonal harm, which is the use of technology to create a disadvantage to certain people that negatively affects their
relationships with others or causes a loss of one's
sense of self and agency. All of these harms are examples of how using technology irresponsibly can negatively impact
people and communities. If used without human
intervention or critical thinking, AI can reinforce systemic bias, leading to unfair
distribution of resources, the perpetuation of dangerous stereotypes, or the reinforcement of
ongoing power dynamics. The good news is that AI
tools are rapidly evolving based on feedback from users. That's why being aware of potential harm and negative outcomes is a first step to using AI responsibly.